{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f0e9cb8",
   "metadata": {},
   "source": [
    "## MLFlow avec Pyspark\n",
    "\n",
    "Avant de commencer, installez Spark en local en suivant le guide \"Spark Installation.pdf\"\n",
    "\n",
    "Nous allons suivre la même démarche que nous avons utilisé dans le premier notebook. \n",
    "\n",
    "Nous allons utilisé aussi le même dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04271821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark #\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "import seaborn as sns\n",
    "import sklearn #\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import matplotlib #\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "os.environ[\"SPARK_LOCAL_IP\"]='127.0.0.1'\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext._conf.getAll()\n",
    "print(\"pyspark: {}\".format(pyspark.__version__))\n",
    "print(\"matplotlib: {}\".format(matplotlib.__version__))\n",
    "print(\"seaborn: {}\".format(sns.__version__))\n",
    "print(\"sklearn: {}\".format(sklearn.__version__))\n",
    "print(\"mlflow: {}\".format(mlflow.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/creditcard.csv'\n",
    "df = spark.read.csv(data_path, header = True,\n",
    "inferSchema = True)\n",
    "labelColumn = \"Class\"\n",
    "columns = df.columns\n",
    "numericCols = columns\n",
    "numericCols.remove(\"Time\")\n",
    "numericCols.remove(labelColumn)\n",
    "print(numericCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0be770",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "assemblerInputs = numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs,\n",
    "outputCol=\"features\")\n",
    "stages += [assembler]\n",
    "dfFeatures = df.select(F.col(labelColumn).alias('label'),*numericCols )\n",
    "normal = dfFeatures.filter(\"Class == 0\").sample(withReplacement=False, fraction=0.5, seed=2020)\n",
    "anomaly = dfFeatures.filter(\"Class == 1\")\n",
    "normal_train, normal_test = normal.randomSplit([0.8, 0.2],seed = 2020)\n",
    "anomaly_train, anomaly_test = anomaly.randomSplit([0.8, 0.2],seed = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e408d9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFeatures.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = normal_train.union(anomaly_train)\n",
    "test_set = normal_test.union(anomaly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75009c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(dfFeatures)\n",
    "train_set = pipelineModel.transform(train_set)\n",
    "test_set = pipelineModel.transform(test_set)\n",
    "selectedCols = ['label', 'features'] + numericCols\n",
    "train_set = train_set.select(selectedCols)\n",
    "test_set = test_set.select(selectedCols)\n",
    "print(\"Training Dataset Count: \", train_set.count())\n",
    "print(\"Test Dataset Count: \", test_set.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd590f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(spark_model, train_set):\n",
    "    trained_model = spark_model.fit(train_set)\n",
    "    trainingSummary = trained_model.summary\n",
    "    pyspark_auc_score = trainingSummary.areaUnderROC\n",
    "    mlflow.log_metric(\"train_acc\", trainingSummary.accuracy)\n",
    "    mlflow.log_metric(\"train_AUC\", pyspark_auc_score)\n",
    "    mlflow.log_\n",
    "    print(\"Training Accuracy: \", trainingSummary.accuracy)\n",
    "    print(\"Training AUC:\", pyspark_auc_score)\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c79071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(spark_model, test_set):\n",
    "    evaluation_summary = spark_model.evaluate(test_set)\n",
    "    eval_acc = evaluation_summary.accuracy\n",
    "    eval_AUC = evaluation_summary.areaUnderROC\n",
    "    mlflow.log_metric(\"eval_acc\", eval_acc)\n",
    "    mlflow.log_metric(\"eval_AUC\", eval_AUC)\n",
    "    print(\"Evaluation Accuracy: \", eval_acc)\n",
    "    print(\"Evaluation AUC: \", eval_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b23638",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol ='label', maxIter=10)\n",
    "mlflow.set_experiment(\"PySpark_CreditCard\")\n",
    "with mlflow.start_run():\n",
    "    trainedLR = train(lr, train_set)\n",
    "    evaluate(trainedLR, test_set)\n",
    "    mlflow.spark.log_model(trainedLR,\"creditcard_model_pyspark\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5588b788",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "\n",
    "copiez l'ID run a partir de l'interface MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlflow.spark.load_model(\"runs:/votre_RUN_ID/creditcard_model_pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_set)\n",
    "y_true = predictions.select(['label']).collect()\n",
    "y_pred = predictions.select(['prediction']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78915eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AUC Score: {roc_auc_score(y_true, y_pred):.3%}\")\n",
    "print(f\"Accuracy Score: {accuracy_score(y_true, y_pred):.3%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "ax = sns.heatmap(conf_matrix, annot=True,fmt='g')\n",
    "ax.invert_xaxis()\n",
    "ax.invert_yaxis()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8c48d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb8787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
